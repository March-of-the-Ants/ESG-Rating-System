{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word2vec으로 e,s,g 단어집 만들기\n",
    "2022/12/29\n",
    "\n",
    "- cbow, skip gram 둘다 진행\n",
    "- e : 환경, 친환경 \n",
    "- s : 사회, 근로\n",
    "- g : 경영, 지배 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- news 데이터로 단어집 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21761"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# news data 불러오기\n",
    "news=pd.read_csv('./news_tb.csv')\n",
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>CmpID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1129</td>\n",
       "      <td>2021</td>\n",
       "      <td>포스코ICT, 카카오워크 통해 RPA 서비스 시작</td>\n",
       "      <td>포스코 의 업무자동화 소프트웨어 로봇인 솔루션과 카카오워크간 연동 서비스가 시작된다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>218</td>\n",
       "      <td>2021</td>\n",
       "      <td>그리티, 특별관계자 지분변동</td>\n",
       "      <td>그리티는 문영우 및 특별관계자의 지분율이 에서 로 변동했다고 일 공시했다 한편 그리...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1129</td>\n",
       "      <td>2021</td>\n",
       "      <td>포스코ICT, 2021 기술 컨퍼런스 개최</td>\n",
       "      <td>포스코대표 정덕균가 지난 일 올해 추진된 기술개발 성과를 공유하고 최신 기술동향과 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "      <td>[코스닥 대표 인터뷰]임형섭 석경에이티 대표 \"25년 나노 소재 노하우로 5G 시장...</td>\n",
       "      <td>파이낸셜뉴스우리나라에서 년 처음 시작해 년 간 나노 소재를 하고 있습니다 등의 가치...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>218</td>\n",
       "      <td>2021</td>\n",
       "      <td>그리티, 특별관계자 지분변동</td>\n",
       "      <td>그리티는 문영우 및 특별관계자의 지분율이 에서 로 변동했다고 일 공시했다 한편 그리...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ID  CmpID  Year  \\\n",
       "0           0   1   1129  2021   \n",
       "1           1   2    218  2021   \n",
       "2           2   3   1129  2021   \n",
       "3           3   4      2  2021   \n",
       "4           4   5    218  2021   \n",
       "\n",
       "                                               Title  \\\n",
       "0                        포스코ICT, 카카오워크 통해 RPA 서비스 시작   \n",
       "1                                    그리티, 특별관계자 지분변동   \n",
       "2                            포스코ICT, 2021 기술 컨퍼런스 개최   \n",
       "3  [코스닥 대표 인터뷰]임형섭 석경에이티 대표 \"25년 나노 소재 노하우로 5G 시장...   \n",
       "4                                    그리티, 특별관계자 지분변동   \n",
       "\n",
       "                                             Content  \n",
       "0  포스코 의 업무자동화 소프트웨어 로봇인 솔루션과 카카오워크간 연동 서비스가 시작된다...  \n",
       "1  그리티는 문영우 및 특별관계자의 지분율이 에서 로 변동했다고 일 공시했다 한편 그리...  \n",
       "2  포스코대표 정덕균가 지난 일 올해 추진된 기술개발 성과를 공유하고 최신 기술동향과 ...  \n",
       "3  파이낸셜뉴스우리나라에서 년 처음 시작해 년 간 나노 소재를 하고 있습니다 등의 가치...  \n",
       "4  그리티는 문영우 및 특별관계자의 지분율이 에서 로 변동했다고 일 공시했다 한편 그리...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(news.isnull().values.any()) #결측값 없음, 숫자, 영어 제거된 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21761/21761 [22:06<00:00, 16.40it/s]  \n"
     ]
    }
   ],
   "source": [
    "#로컬에 저장한 mecab 파일 경로 지정해주기\n",
    "# 형태소분석기 okt 활용 토큰화 작업\n",
    " \n",
    "from konlpy.tag import Okt, Mecab\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "tokenized_data = []\n",
    "for sentence in tqdm(news['Content']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True) # 토큰화\n",
    "    #stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords] # 불용어 제거\n",
    "    #tokenized_data.append(stopwords_removed_sentence)\n",
    "    tokenized_data.append(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 뉴스 데이터 학습시키기\n",
    "#https://hoonzi-text.tistory.com/2 파라미터 정리 \n",
    "# size : 벡터 차원수 ,\n",
    "# window : 훈련시 앞 뒤로 고려하는 단어의 개수\n",
    "# min_count :최소빈도수 , 해당 빈도수보다 작게 등장한 단어 제외\n",
    "# worker : 병렬처리할 스레드 수 \n",
    "#sg : 분석방법론 , 1 = skip-gram, 0=cbow\n",
    "#iter 학습횟수\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#cbow\n",
    "model=Word2Vec(tokenized_data, vector_size=100, window=3, min_count=5,workers=4, sg=0,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27429, 100)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_친환경=model.wv.most_similar(\"친환경\",topn=50)\n",
    "e_환경=model.wv.most_similar(\"환경\",topn=50)\n",
    "s_사회=model.wv.most_similar(\"사회\",topn=50)\n",
    "s_근로=model.wv.most_similar(\"근로\",topn=50)\n",
    "g_경영=model.wv.most_similar(\"경영\",topn=50)\n",
    "g_지배=model.wv.most_similar(\"지배\",topn=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dict(df):\n",
    "    temp = []\n",
    "    for word, percent in df:\n",
    "        temp.append(word)\n",
    "    df = temp\n",
    "    return df\n",
    "\n",
    "e_친환경df=make_dict(e_친환경)\n",
    "e_환경df=make_dict(e_환경)\n",
    "s_근로df=make_dict(s_근로)\n",
    "s_사회df=make_dict(s_사회)\n",
    "g_지배df=make_dict(g_지배)\n",
    "g_경영df=make_dict(g_경영)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_df=pd.DataFrame(zip(e_친환경df, e_환경df,s_근로df,s_사회df,g_지배df,g_경영df))\n",
    "esg_df.columns=['e_친환경','e_환경','s_근로','s_사회','g_지배','g_경영']\n",
    "esg_df.to_csv('./esg_dict_ver1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 저장\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model.wv.save_word2vec_format('news_w2v') # 모델 저장\n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"news_w2v\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 뉴스 데이터 학습시키기\n",
    "#https://hoonzi-text.tistory.com/2 파라미터 정리 \n",
    "# size : 벡터 차원수 ,\n",
    "# window : 훈련시 앞 뒤로 고려하는 단어의 개수\n",
    "# min_count :최소빈도수 , 해당 빈도수보다 작게 등장한 단어 제외\n",
    "# worker : 병렬처리할 스레드 수 \n",
    "#sg : 분석방법론 , 1 = skip-gram, 0=cbow\n",
    "#iter 학습횟수\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#skip gram\n",
    "model2=Word2Vec(tokenized_data, vector_size=100, window=3, min_count=5,workers=4, sg=1,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('변화', 0.5579166412353516), ('민첩성', 0.5516247153282166), ('탄력성', 0.5371886491775513), ('백오피스', 0.5367226600646973), ('여건', 0.5285210013389587), ('스마트워크', 0.5277842283248901), ('인프라', 0.5199689269065857), ('악천후', 0.5175926685333252), ('오염시키다', 0.5136458873748779), ('안전하다', 0.5121936202049255)]\n",
      "[('경영', 0.6901301741600037), ('사회', 0.5772139430046082), ('지배', 0.5631550550460815), ('책임', 0.545724093914032), ('지주회사', 0.5374337434768677), ('구조', 0.5149639248847961), ('지주사', 0.5120095014572144), ('차입', 0.5014294981956482), ('건전성', 0.49147123098373413), ('폐쇄적', 0.4893702268600464)]\n",
      "[('공헌', 0.6660206317901611), ('활동', 0.6133454442024231), ('대타협', 0.6041689515113831), ('나눔', 0.6019120812416077), ('지배구조', 0.5772138237953186), ('실천', 0.5711150169372559), ('문미숙', 0.545948326587677), ('국제사회', 0.5429704785346985), ('지역', 0.539405107498169), ('책임', 0.5369611382484436)]\n"
     ]
    }
   ],
   "source": [
    "print(model2.wv.most_similar(\"환경\"))\n",
    "print(model2.wv.most_similar(\"지배구조\"))\n",
    "print(model2.wv.most_similar(\"사회\"))\n",
    "\n",
    "#모델 저장\n",
    "\n",
    "model2.wv.save_word2vec_format('news_skipgram_w2v') # 모델 저장\n",
    "loaded_model2 = KeyedVectors.load_word2vec_format(\"news_skipgram_w2v\") # 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words1 = list(model.wv.vocab)\n",
    "print(words1)\n",
    "words2 = list(model2.wv.vocab)\n",
    "print(words2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- news, jobplanet, dart , patent text 데이터로 단어집 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "import pandas as pd\n",
    "news=pd.read_csv('./news_tb.csv')\n",
    "jobplanet=pd.read_csv('./jobplanet_tb.csv')\n",
    "dart=pd.read_csv('./dart_tb.csv')\n",
    "patent=pd.read_csv('./patent_tb.csv')\n",
    "all=pd.concat([news['Content'],jobplanet['Review'],dart['EmphsMatter'],patent['Content']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 93414 entries, 0 to 10295\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   contents  92247 non-null  object\n",
      "dtypes: object(1)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_df=pd.DataFrame(all)\n",
    "all_df.columns = ['contents']\n",
    "all_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "contents    1167\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(all_df.isnull().values.any()) #결측값 있음, 숫자, 영어 제거된 상태\n",
    "print(all_df.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contents    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_df=all_df.dropna(axis=0)\n",
    "print(all_df.isnull().sum()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 92247/92247 [01:34<00:00, 975.57it/s] \n"
     ]
    }
   ],
   "source": [
    "#로컬에 저장한 mecab 파일 경로 지정해주기\n",
    "# 형태소분석기 mecab 활용 토큰화 작업\n",
    " \n",
    "from konlpy.tag import Okt, Mecab\n",
    "from tqdm import tqdm\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "#okt = Okt()\n",
    "mecab = Mecab(dicpath=r\"C:\\mecab\\mecab-ko-dic\")\n",
    "\n",
    "tokenized_data = []\n",
    "for sentence in tqdm(all_df['contents']):\n",
    "    if len(sentence) > 1:\n",
    "        tokenized_sentence = mecab.morphs(sentence) # 토큰화\n",
    "        tokenized_data.append(tokenized_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화된 뉴스 데이터 학습시키기\n",
    "#https://hoonzi-text.tistory.com/2 파라미터 정리 \n",
    "# size : 벡터 차원수 ,\n",
    "# window : 훈련시 앞 뒤로 고려하는 단어의 개수\n",
    "# min_count :최소빈도수 , 해당 빈도수보다 작게 등장한 단어 제외\n",
    "# worker : 병렬처리할 스레드 수 \n",
    "#sg : 분석방법론 , 1 = skip-gram, 0=cbow\n",
    "#iter or epochs : 학습횟수\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "#cbow \n",
    "model=Word2Vec(tokenized_data, vector_size=100, window=3, min_count=5,workers=4, sg=0,epochs=100) #window 3\n",
    "model_2=Word2Vec(tokenized_data, vector_size=100, window=5, min_count=5,workers=4, sg=0,epochs=100) #window 5\n",
    "\n",
    "e_친환경=model.wv.most_similar(\"친환경\",topn=50)\n",
    "e_환경=model.wv.most_similar(\"환경\",topn=50)\n",
    "s_사회=model.wv.most_similar(\"사회\",topn=50)\n",
    "s_근로=model.wv.most_similar(\"근로\",topn=50)\n",
    "g_경영=model.wv.most_similar(\"경영\",topn=50)\n",
    "g_지배=model.wv.most_similar(\"지배\",topn=50)\n",
    "\n",
    "\n",
    "e_친환경2=model_2.wv.most_similar(\"친환경\",topn=50)\n",
    "e_환경2=model_2.wv.most_similar(\"환경\",topn=50)\n",
    "s_사회2=model_2.wv.most_similar(\"사회\",topn=50)\n",
    "s_근로2=model_2.wv.most_similar(\"근로\",topn=50)\n",
    "g_경영2=model_2.wv.most_similar(\"경영\",topn=50)\n",
    "g_지배2=model_2.wv.most_similar(\"지배\",topn=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dict(df):\n",
    "    temp = []\n",
    "    for word, percent in df:\n",
    "        temp.append(word)\n",
    "    df = temp\n",
    "    return df\n",
    "\n",
    "#window 3\n",
    "\n",
    "e_친환경df=make_dict(e_친환경)\n",
    "e_환경df=make_dict(e_환경)\n",
    "s_근로df=make_dict(s_근로)\n",
    "s_사회df=make_dict(s_사회)\n",
    "g_지배df=make_dict(g_지배)\n",
    "g_경영df=make_dict(g_경영)\n",
    "\n",
    "\n",
    "esg_df=pd.DataFrame(zip(e_친환경df, e_환경df,s_근로df,s_사회df,g_지배df,g_경영df))\n",
    "esg_df.columns=['e_친환경','e_환경','s_근로','s_사회','g_지배','g_경영']\n",
    "esg_df.to_csv('./all_esg_dict_mecab_win3_ver2.csv')\n",
    "\n",
    "\n",
    "#window 5\n",
    "\n",
    "e_친환경df2=make_dict(e_친환경2)\n",
    "e_환경df2=make_dict(e_환경2)\n",
    "s_근로df2=make_dict(s_근로2)\n",
    "s_사회df2=make_dict(s_사회2)\n",
    "g_지배df2=make_dict(g_지배2)\n",
    "g_경영df2=make_dict(g_경영2)\n",
    "\n",
    "\n",
    "esg_df2=pd.DataFrame(zip(e_친환경df2, e_환경df2,s_근로df2,s_사회df2,g_지배df2,g_경영df2))\n",
    "esg_df2.columns=['e_친환경','e_환경','s_근로','s_사회','g_지배','g_경영']\n",
    "esg_df2.to_csv('./all_esg_dict_mecab_win5_ver3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip gram \n",
    "\n",
    "model_3=Word2Vec(tokenized_data, vector_size=100, window=5, min_count=5,workers=4, sg=1,epochs=100)\n",
    "\n",
    "e_친환경3=model_3.wv.most_similar(\"친환경\",topn=50)\n",
    "e_환경3=model_3.wv.most_similar(\"환경\",topn=50)\n",
    "s_사회3=model_3.wv.most_similar(\"사회\",topn=50)\n",
    "s_근로3=model_3.wv.most_similar(\"근로\",topn=50)\n",
    "g_경영3=model_3.wv.most_similar(\"경영\",topn=50)\n",
    "g_지배3=model_3.wv.most_similar(\"지배\",topn=50)\n",
    "\n",
    "def make_dict(df):\n",
    "    temp = []\n",
    "    for word, percent in df:\n",
    "        temp.append(word)\n",
    "    df = temp\n",
    "    return df\n",
    "\n",
    "\n",
    "e_친환경df3=make_dict(e_친환경3)\n",
    "e_환경df3=make_dict(e_환경3)\n",
    "s_근로df3=make_dict(s_근로3)\n",
    "s_사회df3=make_dict(s_사회3)\n",
    "g_지배df3=make_dict(g_지배3)\n",
    "g_경영df3=make_dict(g_경영3)\n",
    "\n",
    "\n",
    "esg_df3=pd.DataFrame(zip(e_친환경df3, e_환경df3,s_근로df3,s_사회df3,g_지배df3,g_경영df3))\n",
    "esg_df3.columns=['e_친환경','e_환경','s_근로','s_사회','g_지배','g_경영']\n",
    "esg_df3.to_csv('./all_esg_dict_mecab_skip_ver4.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText 로 e,s,g 단어집 만들기\n",
    "- cbow, skip gram 둘다 진행\n",
    "- e : 환경, 친환경 \n",
    "- s : 사회, 근로\n",
    "- g : 경영, 지배 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "\n",
    "model_4 = FastText(tokenized_data, window=5, min_count=5, sg=0) #cbow\n",
    "#model_4 = FastText(tokenized_data, window=5, min_count=5, sg=1)# skip gram\n",
    "\n",
    "e_친환경4=model_4.wv.most_similar(\"친환경\",topn=50)\n",
    "e_환경4=model_4.wv.most_similar(\"환경\",topn=50)\n",
    "s_사회4=model_4.wv.most_similar(\"사회\",topn=50)\n",
    "s_근로4=model_4.wv.most_similar(\"근로\",topn=50)\n",
    "g_경영4=model_4.wv.most_similar(\"경영\",topn=50)\n",
    "g_지배4=model_4.wv.most_similar(\"지배\",topn=50)\n",
    "\n",
    "def make_dict(df):\n",
    "    temp = []\n",
    "    for word, percent in df:\n",
    "        temp.append(word)\n",
    "    df = temp\n",
    "    return df\n",
    "\n",
    "\n",
    "e_친환경df4=make_dict(e_친환경4)\n",
    "e_환경df4=make_dict(e_환경4)\n",
    "s_근로df4=make_dict(s_근로4)\n",
    "s_사회df4=make_dict(s_사회4)\n",
    "g_지배df4=make_dict(g_지배4)\n",
    "g_경영df4=make_dict(g_경영4)\n",
    "\n",
    "\n",
    "esg_df4=pd.DataFrame(zip(e_친환경df4, e_환경df4,s_근로df4,s_사회df4,g_지배df4,g_경영df4))\n",
    "esg_df4.columns=['e_친환경','e_환경','s_근로','s_사회','g_지배','g_경영']\n",
    "esg_df4.to_csv('./all_esg_dict_mecab_fast_cbow.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
